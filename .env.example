# GitHub Personal Access Token for collecting repositories
# Required for scripts/collect_github_repos.py
# Create at: https://github.com/settings/tokens (needs repo:read scope)
GITHUB_PAT=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Hugging Face Token for model downloads and pushing
# Required for downloading gated models and pushing to Hub
# Create at: https://huggingface.co/settings/tokens
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Directory paths
DATA_DIR=./data
OUTPUT_DIR=./outputs

# Model configuration
MODEL_ID=nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16

# vLLM server configuration
VLLM_PORT=8000
VLLM_HOST=0.0.0.0
VLLM_GPU_MEMORY_UTILIZATION=0.90

# Node.js version for repo-based evaluation tasks
NODE_VERSION=24

# NeMo Evaluator configuration
NEMO_EVAL_API_KEY=EMPTY

# Training configuration
TRAIN_BATCH_SIZE=1
TRAIN_GRADIENT_ACCUMULATION_STEPS=8
TRAIN_LEARNING_RATE=2e-5
TRAIN_NUM_EPOCHS=3

# QLoRA configuration
QLORA_R=64
QLORA_ALPHA=16
QLORA_DROPOUT=0.05

# Wandb (optional, for experiment tracking)
WANDB_PROJECT=nemotron-ts-posttrain
WANDB_ENTITY=
WANDB_API_KEY=
